{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"format1.5-WebScrape.ipynb","provenance":[],"collapsed_sections":[],"mount_file_id":"1RbDWoswd0FPFVTygHc0wu5KaGjnxhMAQ","authorship_tag":"ABX9TyNv2QVwBEGzAytQThBfdM2P"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"zhGOEFrk7ox6"},"source":["# Import libraries\n","import requests\n","import urllib.request\n","import time\n","from bs4 import BeautifulSoup\n","from google.colab import files\n","\n","\n","catalog_links = \"\"\n","path = \"/content/drive/My Drive/US College Catalogs/MA/Scrape Links/\"\n","#------------------------------------\n","path_school = \"Fisher College/\"\n","#------------------------------------\n","path_file = \"list.txt\"\n","\n","with open(path + path_school + path_file, \"r\") as f:\n","  user_text = f.read()\n","#parse string into list\n","list_url_years = user_text.split()\n","for i in list_url_years:\n","  print(i)\n","\n","#----------------------------------------------\n","url_main = \"\"\n","#----------------------------------------------"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZmyPpkY77vi9"},"source":["# First iteration:\n","# Gets links from first page year\n","url_get_text1 = []\n","\n","for page in list_url_years:\n","  response = requests.get(page)\n","  download_url = []\n","  soup = BeautifulSoup(response.text,'html.parser')\n","  #-------------------------------------------------\n","  result = soup.findAll(class_=\"et_post_meta_wrapper\")\n","  #-------------------------------------------------\n","  soup = BeautifulSoup(str(result),'html.parser')\n","  for one_a_tag in soup.findAll('a'):\n","    try:\n","      link = one_a_tag['href']\n","      #print(url_main + link)\n","      download_url.append(url_main + link)\n","    except:\n","      print(\"link not found\")\n","  url_get_text1.append(download_url)\n","\n","# for j in url_get_text1:\n","#   for i in range(15):\n","#     j.pop(0)\n","# url_get_text1 = []\n","\n","# print(\"-------\")\n","# for i in list_url_years:\n","#   download_url = []\n","#   download_url.append(i)\n","#   url_get_text1.append(download_url)\n","for i in url_get_text1:\n","  print(i)\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"jzNwZskD70Fu"},"source":["final = \"\"\n","try:\n","  response = requests.get(url_get_text1[0][0])\n","  soup = BeautifulSoup(response.text, 'html.parser')\n","  #----------------------------------------------\n","  result = soup.findAll(class_=\"maryann_academic_side\")\n","  # print(\"result = \",result)\n","  # print(\"=====================result\")\n","  #----------------------------------------------\n","  soup = BeautifulSoup(str(result),'html.parser')\n","  for one_a_tag in soup.findAll('a'):  #'a' tags are for links\n","    try:\n","      link = one_a_tag['href']\n","      print(url_get_text1[0][0] + link)\n","      print(\"=========================link\")\n","\n","      response_out = requests.get(url_get_text1[0][0] + link)\n","      soup_out = BeautifulSoup(response_out.text, 'html.parser')\n","      #----------------------------------------------\n","      course_desc = soup_out.findAll(class_=\"maryann_course_entry\")\n","      # print(\"course_desc = \", course_desc)\n","      # print(\"=========================course_desc \")\n","      #----------------------------------------------\n","      soup_out = BeautifulSoup(str(course_desc), 'html.parser')\n","      raw_text = soup_out.get_text()\n","      # print(\"raw_text = \",raw_text)\n","      # print(\"=========================raw_text \")\n","      final = final + raw_text\n","    except:\n","      print(\"could not access link:\",url_get_text1[0][0] + link)\n","except:\n","  print(\"could not access link:\",page)\n","print(final)\n","print(\"=========================final \")"],"execution_count":null,"outputs":[]}]}